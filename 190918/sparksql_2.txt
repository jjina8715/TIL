scala> val rowRDD = pidAndCntDF.rdd
rowRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[15] at rdd at <console>:25

scala> val pidAndCntRDD = rowRDD.map{row=>
     | val date = row.get(0)
     | val cnt = row.get(1)
     | (date, cnt)}
pidAndCntRDD: org.apache.spark.rdd.RDD[(Any, Any)] = MapPartitionsRDD[24] at map at <console>:25

scala> pidAndCntRDD.collect.foreach(println)
(p001,84)
(p009,80)
(p008,80)
(p007,71)
(p002,66)
(p010,58)
(p003,54)
(p006,51)
(p004,50)
(p011,49)
(p005,43)
(p012,39)
(p014,10)
(p015,7)
(p013,4)
