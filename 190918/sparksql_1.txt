scala> case class Product(date: String, pid: String)
defined class Product

scala> val productRDD = sc.textFile("/edudata/product_click.log")
productRDD: org.apache.spark.rdd.RDD[String] = /edudata/product_click.log MapPartitionsRDD[41] at textFile at <console>:24

scala> val productDF = productRDD.map{record=>
     | val splitRecord = record.split(" ")
     | val date = splitRecord(0)
     | val pid = splitRecord(1)
     | Product(date, pid)}.toDF
productDF: org.apache.spark.sql.DataFrame = [date: string, pid: string]

scala> val pidAndCntDF = productDF.groupBy($"pid").agg(count($"pid") as "cnt").orderBy($"cnt".desc)
scala> pidAndCntDF.show
| pid|cnt|
+----+---+
|p001| 84|
|p008| 80|
|p009| 80|
|p007| 71|
|p002| 66|
|p010| 58|
|p003| 54|
|p006| 51|
|p004| 50|
|p011| 49|
|p005| 43|
|p012| 39|
|p014| 10|
|p015|  7|
|p013|  4|
+----+---+
